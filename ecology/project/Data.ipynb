{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import afscgap\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def give_it_a_go(result, method_name, **kwargs):\n",
    "    try:\n",
    "        return getattr(result, method_name)(**kwargs)\n",
    "    except AssertionError:\n",
    "        return None\n",
    "\n",
    "def to_dict(result):\n",
    "    \"\"\"\n",
    "    Convert a single result to a dictionary.\n",
    "\n",
    "    (The .to_dict() method of the Result object does not work as expected.)\n",
    "    \"\"\"\n",
    "    return {\n",
    "            'year': give_it_a_go(result, 'get_year'),\n",
    "            'srvy': give_it_a_go(result, 'get_srvy'),\n",
    "            'survey': give_it_a_go(result, 'get_survey'),\n",
    "            'survey_id': give_it_a_go(result, 'get_survey_id'),\n",
    "            'cruise': give_it_a_go(result, 'get_cruise'),\n",
    "            'haul': give_it_a_go(result, 'get_haul'),\n",
    "            'stratum': give_it_a_go(result, 'get_stratum'),\n",
    "            'station': give_it_a_go(result, 'get_station'),\n",
    "            'vessel_name': give_it_a_go(result, 'get_vessel_name'),\n",
    "            'vessel_id': give_it_a_go(result, 'get_vessel_id'),\n",
    "            'date_time': give_it_a_go(result, 'get_date_time'),\n",
    "            'latitude_dd': give_it_a_go(result, 'get_latitude'),\n",
    "            'longitude_dd': give_it_a_go(result, 'get_longitude'),\n",
    "            'species_code': give_it_a_go(result, 'get_species_code'),\n",
    "            'common_name': give_it_a_go(result, 'get_common_name'),\n",
    "            'scientific_name': give_it_a_go(result, 'get_scientific_name'),\n",
    "            'taxon_confidence': give_it_a_go(result, 'get_taxon_confidence'),\n",
    "            'cpue_kgha': give_it_a_go(result, 'get_cpue_weight_maybe', units='kg/ha'),\n",
    "            'cpue_kgkm2': give_it_a_go(result, 'get_cpue_weight_maybe', units='kg/km2'),\n",
    "            'cpue_kg1000km2': give_it_a_go(result, 'get_cpue_weight_maybe', units='kg1000/km2'),\n",
    "            'cpue_noha': give_it_a_go(result, 'get_cpue_count_maybe', units='count/ha'),\n",
    "            'cpue_nokm2': give_it_a_go(result, 'get_cpue_count_maybe', units='count/km2'),\n",
    "            'cpue_no1000km2': give_it_a_go(result, 'get_cpue_count_maybe', units='count1000/km2'),\n",
    "            'weight_kg': give_it_a_go(result, 'get_weight_maybe', units='kg'), # changed this from get_weight\n",
    "            'count': give_it_a_go(result, 'get_count_maybe'), # changed this from get_count\n",
    "            'bottom_temperature_c': give_it_a_go(result, 'get_bottom_temperature_maybe',\n",
    "                units='c'\n",
    "            ),\n",
    "            'surface_temperature_c': give_it_a_go(result, 'get_surface_temperature_maybe',\n",
    "                units='c'\n",
    "            ),\n",
    "            'depth_m': give_it_a_go(result, 'get_depth', units='m'),\n",
    "            'distance_fished_km': give_it_a_go(result, 'get_distance_fished', units='km'),\n",
    "            'net_width_m': give_it_a_go(result, 'get_net_width', units='m'),\n",
    "            'net_height_m': give_it_a_go(result, 'get_net_height', units='m'),\n",
    "            'area_swept_ha': give_it_a_go(result, 'get_area_swept', units='ha'),\n",
    "            'duration_hr': give_it_a_go(result, 'get_duration', units='hr')\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = list(range(1982, 2025))\n",
    "print(len(years))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for year in tqdm(years):\n",
    "    try:\n",
    "        file_path = f'data/raw_year_{year}.gz'\n",
    "        if os.path.exists(file_path):\n",
    "            continue\n",
    "        query = afscgap.Query()\n",
    "        query.filter_year(eq=year)\n",
    "        query.set_presence_only(False)\n",
    "        results = query.execute()\n",
    "\n",
    "        rows = [\n",
    "            to_dict(result)\n",
    "            for result in results\n",
    "        ]\n",
    "\n",
    "        data = pd.DataFrame(rows)\n",
    "        data.to_csv(file_path, index=False)\n",
    "    except Exception as e:\n",
    "        print(f'Failed to fetch data for year {year}')\n",
    "        print(e)\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/raw_year_1982.gz')\n",
    "data['taxon_confidence'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []\n",
    "for year in tqdm(years):\n",
    "    try:\n",
    "        file_path = f'data/raw_year_{year}.gz'\n",
    "        df = pd.read_csv(file_path)\n",
    "        df = df[['year', 'scientific_name', 'cpue_kgha', 'taxon_confidence']]\n",
    "        dfs.append(df)\n",
    "    except pd.errors.EmptyDataError:\n",
    "        continue\n",
    "\n",
    "data = pd.concat(dfs)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['scientific_name'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data[data['cpue_kgha'] > 0]\n",
    "df['taxon_confidence'] = df['taxon_confidence'].fillna('Unknown')\n",
    "df['taxon_confidence'] = df['taxon_confidence'].isin(['High', 'Moderate'])\n",
    "df = (\n",
    "    df.groupby(['scientific_name', 'taxon_confidence']).size().reset_index().rename(columns={0: 'count'}).sort_values('count', ascending=False)\n",
    "    .merge(df.groupby(['scientific_name']).size().reset_index().rename(columns={0: 'total_count'}), on='scientific_name')\n",
    "    .assign(percentage=lambda x: x['count'] / x['total_count'])\n",
    "    .sort_values('percentage', ascending=False)\n",
    ")\n",
    "df = df[df['taxon_confidence']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.ecdf(df, x=\"percentage\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['scientific_name'].isin(df[df['percentage'] >= 0.95]['scientific_name'].unique())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "species = set(df[df['percentage'] >= 0.95]['scientific_name'].unique())\n",
    "len(species)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_confidence_species = set(s for s in species if 'sp.' not in s and ' ' in s)\n",
    "len(high_confidence_species)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []\n",
    "for year in tqdm(years):\n",
    "    try:\n",
    "        file_path = f'data/raw_year_{year}.gz'\n",
    "        df = pd.read_csv(file_path)\n",
    "        df = df[['year', 'station', 'stratum', 'haul']]\n",
    "        dfs.append(df)\n",
    "    except pd.errors.EmptyDataError:\n",
    "        continue\n",
    "\n",
    "hauls = pd.concat(dfs)\n",
    "hauls = hauls.drop_duplicates()\n",
    "hauls.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hauls.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hauls['station'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = (\n",
    "    data[(data['cpue_kgha'] > 0) & data['scientific_name'].isin(high_confidence_species)].groupby(['scientific_name']).size().reset_index().rename(columns={0: 'count'}).sort_values('count', ascending=False)\n",
    ")\n",
    "df['occurrence_likelihood'] = df['count'] / hauls.shape[0]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.ecdf(df, x=\"occurrence_likelihood\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_species = set(df[df['occurrence_likelihood'] >= 0.05]['scientific_name'].unique())\n",
    "len(chosen_species)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pulling the Columns We Care About"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/raw_year_1982.gz')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.groupby(['stratum'])['survey'].nunique().describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['stratum'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\n",
    "    'year', 'haul', 'station', # identifies the haul\n",
    "    'srvy', 'stratum', # identifies the survey area\n",
    "    'distance_fished_km', 'duration_hr', # haul speed information\n",
    "    'surface_temperature_c', 'bottom_temperature_c', # temperature information,\n",
    "    'depth_m', # depth information\n",
    "    'scientific_name', 'cpue_kgha', # CPUE information\n",
    "]\n",
    "data[columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []\n",
    "for year in tqdm(years):\n",
    "    try:\n",
    "        file_path = f'data/raw_year_{year}.gz'\n",
    "        df = pd.read_csv(file_path)\n",
    "        df = df[columns]\n",
    "        df = df[df['scientific_name'].isin(chosen_species) & (df['cpue_kgha'] > 0)]\n",
    "        dfs.append(df)\n",
    "    except pd.errors.EmptyDataError:\n",
    "        continue\n",
    "\n",
    "data = pd.concat(dfs)\n",
    "data = data.drop_duplicates()\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = (\n",
    "    data[[c for c in data.columns if c not in ('scientific_name', 'cpue_kgha')]].drop_duplicates(['year', 'station', 'stratum', 'haul'])\n",
    ").merge(\n",
    "    pd.DataFrame({'scientific_name': list(chosen_species)}), how='cross'\n",
    ").merge(\n",
    "    data[['year', 'station', 'stratum', 'haul', 'scientific_name', 'cpue_kgha']]\n",
    "    .drop_duplicates(['year', 'station', 'stratum', 'haul', 'scientific_name']),\n",
    "    how='left'\n",
    ")\n",
    "df['cpue_kgha'] = df['cpue_kgha'].fillna(0.0)\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('data/processed.gz', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Investigating the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df \n",
    "del hauls \n",
    "del data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/processed.gz')\n",
    "print(data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.histogram(data['distance_fished_km'].sample(10000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['kmh'] = data['distance_fished_km'] / data['duration_hr']\n",
    "px.histogram(data['kmh'].sample(10000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.histogram(data['duration_hr'].sample(10000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.histogram(data['surface_temperature_c'].sample(10000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.histogram(data['bottom_temperature_c'].sample(10000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.histogram(data['depth_m'].sample(10000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in ['surface_temperature_c', 'bottom_temperature_c', 'stratum', 'depth_m', 'duration_hr']:\n",
    "    print(f'{column}:')\n",
    "    print(\n",
    "        data[np.isnan(data[column])].shape[0] / data[column].shape[0]\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.shape)\n",
    "data = data.dropna(subset=['surface_temperature_c', 'bottom_temperature_c', 'depth_m', 'duration_hr'])\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = data[['year', 'srvy', 'station', 'stratum', 'haul', 'depth_m', 'duration_hr', 'surface_temperature_c', 'bottom_temperature_c']].drop_duplicates()\n",
    "base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base.drop_duplicates(['year', 'srvy', 'station', 'stratum', 'haul']).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for species in tqdm(list(data['scientific_name'].unique())):\n",
    "    df = data[data['scientific_name'] == species][['year', 'srvy', 'station', 'stratum', 'haul', 'cpue_kgha']]\n",
    "    df = df.rename({'cpue_kgha': species}, axis=1)\n",
    "    base = base.merge(df, on=['year', 'srvy', 'station', 'stratum', 'haul'], how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(base.shape)\n",
    "base.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base.to_csv('data/processed_final.gz', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/processed_final.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['srvy'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []\n",
    "for year in tqdm(years):\n",
    "    try:\n",
    "        file_path = f'data/raw_year_{year}.gz'\n",
    "        df = pd.read_csv(file_path)\n",
    "        df = df[['survey', 'station', 'longitude_dd', 'latitude_dd']].drop_duplicates(['survey', 'station'])\n",
    "        dfs.append(df)\n",
    "    except pd.errors.EmptyDataError:\n",
    "        continue\n",
    "\n",
    "data = pd.concat(dfs).drop_duplicates(['survey', 'station'])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.scatter_geo(\n",
    "    data[['survey', 'station', 'latitude_dd', 'longitude_dd']].drop_duplicates(['survey', 'station']),\n",
    "    lat='latitude_dd',\n",
    "    lon='longitude_dd',\n",
    "    color='survey',\n",
    "    title='Stations by Survey'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/raw_year_2024.gz').drop_duplicates(['survey', 'station'])\n",
    "print(data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "import pandas as pd\n",
    "\n",
    "# Define features to plot\n",
    "features = ['depth_m', 'surface_temperature_c', 'bottom_temperature_c']\n",
    "num_features = len(features)\n",
    "\n",
    "# Create subplots with Cartopy projection\n",
    "fig, axes = plt.subplots(num_features, 1, figsize=(18, 6), subplot_kw={'projection': ccrs.PlateCarree()})\n",
    "\n",
    "for i, feature in enumerate(features):\n",
    "    ax = axes[i]\n",
    "    \n",
    "    # Add map features (coastlines, land, borders)\n",
    "    ax.set_extent([\n",
    "        data[data['longitude_dd'] < 0]['longitude_dd'].min(), \n",
    "        data[data['longitude_dd'] < 0]['longitude_dd'].max(), \n",
    "        data['latitude_dd'].min(),\n",
    "        data['latitude_dd'].max()\n",
    "    ])  # Adjust extent based on your dataset\n",
    "    ax.add_feature(cfeature.COASTLINE)\n",
    "    ax.add_feature(cfeature.LAND, edgecolor='black', facecolor='lightgray')\n",
    "    ax.add_feature(cfeature.BORDERS, linestyle=':')\n",
    "    \n",
    "    # Scatter plot with individual color scale\n",
    "    sc = ax.scatter(data['longitude_dd'], data['latitude_dd'], c=data[feature], cmap='viridis', s=10, transform=ccrs.PlateCarree())\n",
    "\n",
    "    # Add colorbar for each subplot\n",
    "    cbar = plt.colorbar(sc, ax=ax, orientation=\"vertical\", fraction=0.046, pad=0.04)\n",
    "    cbar.set_label(feature)\n",
    "\n",
    "    # Title and labels\n",
    "    #ax.set_title(feature)\n",
    "\n",
    "# Adjust layout for better spacing\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/processed_final.gz')\n",
    "print(data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, num_features, figsize=(18, 6))\n",
    "\n",
    "for i, feature in enumerate(features):\n",
    "    ax = axes[i]\n",
    "    \n",
    "    # Scatter plot with individual color scale\n",
    "    sc = ax.hist(data[feature])\n",
    "\n",
    "    # Add colorbar for each subplot\n",
    "    #cbar = plt.colorbar(sc, ax=ax, orientation=\"vertical\", fraction=0.046, pad=0.04)\n",
    "    #cbar.set_label(feature)\n",
    "    ax.set_title(feature)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "species = list(data.columns[9:])\n",
    "species = sorted([((1 - data[data[s] == 0].shape[0] / data.shape[0]), s) for s in species])\n",
    "soi = species[0], species[len(species) // 2], species[-1]\n",
    "soi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, len(soi), figsize=(18, 6))\n",
    "\n",
    "for i, (prop, species) in enumerate(soi):\n",
    "    ax = axes[i]\n",
    "    \n",
    "    # Scatter plot with individual color scale\n",
    "    sc = ax.hist((data[data[species] > 0][species]) ** (1/4))\n",
    "\n",
    "    # Add colorbar for each subplot\n",
    "    #cbar = plt.colorbar(sc, ax=ax, orientation=\"vertical\", fraction=0.046, pad=0.04)\n",
    "    #cbar.set_label(feature)\n",
    "    ax.set_title(f'{species} ({prop:.2f})')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "((data[data['Albatrossia pectoralis'] > 0]['Albatrossia pectoralis']) ** (1/4)).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = []\n",
    "for species in data.columns[9:]:\n",
    "    rows.append({\n",
    "        'species': species,\n",
    "        'nonzero_percentage': 1 - data[data[species] == 0].shape[0] / data.shape[0],\n",
    "        'cpue_kgha_mean': data[data[species] > 0][species].mean(),\n",
    "        'cpue_kgha_4th_root_std': (data[data[species] > 0][species] ** (1/4)).std(),\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(rows).sort_values('species')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
