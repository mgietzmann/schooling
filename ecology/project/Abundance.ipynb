{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb3249c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import pairwise_distances, explained_variance_score\n",
    "import plotly.express as px\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "984d30ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/processed_final.gz')\n",
    "print(data.shape)\n",
    "data['nothing'] = 0.0\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e88e370",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_features = ['stratum', 'depth_m', 'duration_hr', 'surface_temperature_c', 'bottom_temperature_c']\n",
    "indexes = ['year', 'srvy', 'station', 'haul']\n",
    "species = sorted([c for c in data.columns if c not in (indexes + env_features + ['nothing'])])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44c6f79b",
   "metadata": {},
   "source": [
    "# Abundance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "341cf547",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train, data_test, *_ = train_test_split(data, data, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d544ab7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_features = ['stratum', 'depth_m', 'duration_hr', 'surface_temperature_c', 'bottom_temperature_c']\n",
    "indexes = ['year', 'srvy', 'station', 'haul']\n",
    "species = sorted([c for c in data.columns if c not in (indexes + env_features + ['nothing'])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc873be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([\n",
    "    data[s] ** (1/4) / np.max(data[s] ** (1/4)) for s in species\n",
    "])\n",
    "distance_matrix = pairwise_distances(X, metric='braycurtis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b6ca1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_CLUSTERS = 6\n",
    "\n",
    "model = AgglomerativeClustering(\n",
    "    n_clusters=N_CLUSTERS,\n",
    "    metric='precomputed',\n",
    "    linkage='complete',\n",
    "    compute_distances=True\n",
    ").fit(distance_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a00a62fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_forest(\n",
    "    data_train, data_test, selected, species_features, env_features\n",
    "):\n",
    "    data_train_resample = (\n",
    "        data_train[data_train[selected] > 0]\n",
    "        .sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "    )\n",
    "    data_test_resample = (\n",
    "        data_test[data_test[selected] > 0]\n",
    "        .sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "    )\n",
    "\n",
    "    X_train = data_train_resample[env_features + species_features]\n",
    "    y_train = data_train_resample[selected]\n",
    "\n",
    "    X_test = data_test_resample[env_features + species_features]\n",
    "    y_test = data_test_resample[selected]\n",
    "\n",
    "    forest = RandomForestRegressor(\n",
    "        n_estimators=100,\n",
    "        min_samples_leaf=5,\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "    )\n",
    "    search = RandomizedSearchCV(\n",
    "        forest,\n",
    "        {\n",
    "            'min_samples_leaf': [5, 10, 20],\n",
    "        },\n",
    "        n_iter=3,\n",
    "        refit=True,\n",
    "        cv=3,\n",
    "        verbose=0\n",
    "    )\n",
    "    search.fit(X_train, y_train)\n",
    "    forest = search.best_estimator_\n",
    "    y_pred = forest.predict(X_test)\n",
    "    score = explained_variance_score(y_test, y_pred)\n",
    "    return score\n",
    "\n",
    "for case, features in zip(['cluster_env', 'cluster_species', 'rand_env', 'rand_species'], [env_features, ['nothing'], env_features, ['nothing']]):\n",
    "    print(f'Case: {case}')\n",
    "    selection_rows = []\n",
    "    for i in range(N_CLUSTERS):\n",
    "        left_to_select = list(str(s) for s in np.array(species)[model.labels_ == i])\n",
    "        if case.startswith('rand'):\n",
    "            left_to_select = [str(s) for s in np.random.choice(species, size=len(left_to_select), replace=False)]\n",
    "\n",
    "        for s in left_to_select:\n",
    "            data_train[s] = data_train[s] ** (1/4)\n",
    "            data_test[s] = data_test[s] ** (1/4)\n",
    "\n",
    "        selected = []\n",
    "        scores = []\n",
    "        selected_scores = []\n",
    "        \n",
    "        information = 1.0\n",
    "        marginal_information = 1.0\n",
    "        for j in tqdm(range(len(left_to_select))):\n",
    "            options = []\n",
    "            for new_selection in left_to_select:\n",
    "                species_features = [s for s in left_to_select if s != new_selection]\n",
    "                overall_score = (len(left_to_select) - 1)\n",
    "                selected_score = 0.0\n",
    "                for s in selected + [new_selection]:\n",
    "                    score = train_forest(\n",
    "                        data_train, data_test, s, species_features, features\n",
    "                    )\n",
    "                    overall_score += score\n",
    "                    selected_score += score\n",
    "                overall_score = (overall_score / (len(selected) + len(left_to_select)))\n",
    "                selected_score = selected_score / (len(selected) + 1)\n",
    "                options.append((new_selection, overall_score, selected_score))\n",
    "            best_option = sorted(options, key=lambda x: x[1], reverse=True)[0]\n",
    "\n",
    "            selection_rows.append({\n",
    "                'case': case,\n",
    "                'cluster': i,\n",
    "                'species': best_option[0],\n",
    "                'information': float(information),\n",
    "                'marginal': float(marginal_information),\n",
    "                'species': len(left_to_select) + len(selected) - j,\n",
    "            })\n",
    "            information = best_option[1]\n",
    "            marginal_information = best_option[2]\n",
    "\n",
    "            left_to_select.remove(best_option[0])\n",
    "            selected.append(best_option[0])\n",
    "\n",
    "        selection_rows.append({\n",
    "            'case': case,\n",
    "            'cluster': i,\n",
    "            'species': 'BASE',\n",
    "            'information': float(information),\n",
    "            'marginal': float(marginal_information),\n",
    "            'species': 0,\n",
    "        })\n",
    "        break\n",
    "\n",
    "    selection_df = pd.DataFrame(selection_rows)\n",
    "    selection_df.to_csv(f'abundance_{case}.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa1ace2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
