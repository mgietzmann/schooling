---
title: STAT641 - Homework 4
author: Marcel Gietzmann-Sanders
---

## Problem 1

(a) Finding the expecation and variance of $u$:
$$\mathbb{E}(u)=-2(0.4)+1(0.5)+4(0.1)=0.1$$

$$\mathbb{E}(u^2)=-4(0.4)+1(0.5)+16(0.1)=3.7$$

$$var(u)=\mathbb{E}(u^2) - \mathbb{E}(u)^2=3.7-0.01=3.69$$

(b) Simulating 10,000 draws from this distribution using R we get $\mathbb{E}\approx 0.115$ and $var(u)\approx 3.74$. This is
reasonably close to what we got above. 

```{r, echo=FALSE, results='hide'}
probs <- c(0.4, 0.5, 0.1)
u <- c(-2, 1, 4)

samples <- sample(u, size=10000, prob=probs, replace=TRUE)
(mean(samples))
(var(samples))
```


## Problem 2

(a) Marginal distributions:

$$P(u=-3)=0.35, P(u=0)=0.3, P(u=3)=0.35$$
$$P(v=0)=0.3,P(v=9)=0.7$$

(b) Expectations of $u$ and $v$:

$$\mathbb{E}(u)=-3(0.35)+0(0.3)+3(0.35)=0$$
$$\mathbb{E}(v)=0(0.3)+9(0.7)=6.3$$

(c) Expectations of $uv$, $u^2$, and $v^2$:

$$\mathbb{E}(uv)=-3(0)0-3(9)0.35+0(0)0.3+0(9)0+3(0)0+3(9)0.35=0$$
$$\mathbb{E}(u^2)=9(0.35)+0(0.3)+9(0.35)=6.3$$
$$\mathbb{E}(v^2)=0(0.3)+81(0.7)=56.7$$

(d) Variance, Covariance, and Correlation:

$$var(u)=6.3-0^2=6.3$$
$$var(v)=56.7-6.3^2=17.01$$
$$cov(u,v)=0-0(6.3)=0$$

Given the covariance is 0 the correlation will be 0 as well. 

(e) Given $cor(u,v)=0$ there is no correlation between $u$ and $v$.

(f) For $u$ and $v$ to be independent their joint pmf must be the product of the 
marginal pmf's. However we find: 

$$P(u=-3,v=0)=0 \neq 0.105 = 0.35(0.3) = P(u=-3)P(v=0)$$

Therefore the joint pmf is not the product of the marginal pmf's and so $u$ and $v$ are dependent. 

## Problem 3

(a) Done!
(b) Done!
```{r, echo=FALSE, results='hide', message=FALSE}
library(rjags)
```

(c) Decided to run 100,000 iterations with a thining of 10 for 10,000 samples. 



```{r, echo=FALSE, results='hide', message=FALSE}
data <- list(Y=1, N=15, A=5, B=3)
inits <- list(theta=0.54)
fname <- "binomial-beta-jags-model.txt"
iters <- 100000
thin <- 10

model <- jags.model(
    file=fname, 
    data=data,
    inits=inits,
    n.chains=1,
    n.adapt=1000,
    quiet=FALSE
)
```

```{r, echo=FALSE}
variables <- c("theta", "y.predicted")
samples <- coda.samples(
    model, variables, n.iter = iters, thin = thin
)
theta <- samples[[1]][,"theta"]
plot(theta)
```

(d) Our 95% credible set from our model is (0.105, 0.453)
```{r, echo=FALSE, results='hide', message=FALSE}
quantile(theta, c(0.025, 0.975))
```
(e) The credible set we computed last time was (0.107, 0.454). Compared to our 
(0.105, 0.453) these two sets are very close. 

(f) Plots of our density (solid) and the actual distribution (dashed). 
```{r, echo=FALSE}
hist(theta,probability=TRUE,main="", xlab="theta")
lines(density(theta))
curve(dbeta(x,6,17), add=TRUE, lty=2, lwd=2)
```

To my eye at least it looks like the algorithm has converged as the two curves 
are very close. (There is a little deviation right at the peak) 